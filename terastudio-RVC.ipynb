{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BF667/TSRVC-ipynb/blob/main/terastudio-RVC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVAACnvlmE4I"
      },
      "source": [
        "# **TeraStudio RVC**\n",
        "\n",
        "\n",
        "A simple, high-quality voice conversion tool focused on ease of use and performance.\n",
        "\n",
        "[Support](https://discord.gg/TEywTVdK) ‚Äî [GitHub](https://github.com/terastudio-org/TeraStudio-RVC)\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **Acknowledgments**\n",
        "\n",
        "To all external collaborators for their special help in the following areas:\n",
        "* PhamHuynhAnh16 (Base Project)\n",
        "\n",
        "\n",
        "#### **Disclaimer**\n",
        "By using TeraStudio RVC, you agree to comply with ethical and legal standards, respect intellectual property and privacy rights, avoid harmful or prohibited uses, and accept full responsibility for any outcomes, while TeraStudio RVC disclaims liability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BJeRif5jjL5s"
      },
      "outputs": [],
      "source": [
        "#@title **üåè Setting**\n",
        "import os\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(\"üë©üèª‚Äçüíª C√†i ƒë·∫∑t...\")\n",
        "\n",
        "!git clone https://github.com/terastudio-org/TeraStudio-RVC.git /content/main_core > /dev/null 2>&1\n",
        "!apt-get -y install libportaudio2 -qq > /dev/null 2>&1\n",
        "\n",
        "\n",
        "app_dir = \"content/main_core\"\n",
        "\n",
        "!pip install uv > /dev/null 2>&1\n",
        "!uv pip install -r /content/main_core/requirements.txt --no-cache-dir -q > /dev/null 2>&1\n",
        "\n",
        "#@markdown **üíª Installation will take about 2 minutes to complete!**\n",
        "%cd app_dir\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Ho√†n T·∫•t!\", button_style=\"success\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIsBEvHaQWMJ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **üì± Launch User Interface**\n",
        "import os\n",
        "import json\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "configs_json = os.path.join(\"main\", \"configs\", \"config.json\")\n",
        "\n",
        "def change_language(lang):\n",
        "    configs = json.load(open(configs_json, \"r\"))\n",
        "\n",
        "    if lang != configs[\"language\"]:\n",
        "        configs[\"language\"] = lang\n",
        "\n",
        "        with open(configs_json, \"w\") as f:\n",
        "            json.dump(configs, f, indent=4)\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "#@markdown **To experience all features, use the interface :) For a simpler approach, do not use the interface.**\n",
        "language = \"en-US\" #@param [\"vi-VN\", \"en-US\"]\n",
        "#@markdown **If you know how, you can use charts to check for overfitting üëç**\n",
        "use_charts = False #@param {type:\"boolean\"}\n",
        "\n",
        "if use_charts:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir ./assets/logs --port=6870\n",
        "\n",
        "change_language(language)\n",
        "\n",
        "if not os.path.exists(f\"/content/{app_dir}/assets/models/predictors/rmvpe.pt\"):\n",
        "    !wget https://huggingface.co/AnhP/Vietnamese-RVC-Project/resolve/main/predictors/rmvpe.pt -O /content/Vietnamese_RVC/assets/models/predictors/rmvpe.pt > /dev/null 2>&1\n",
        "\n",
        "if not os.path.exists(f\"/content/{app_dir}/assets/models/embedders/hubert_base.pt\"):\n",
        "    !wget https://huggingface.co/AnhP/Vietnamese-RVC-Project/resolve/main/embedders/fairseq/hubert_base.pt -O /content/Vietnamese_RVC/assets/models/embedders/hubert_base.pt > /dev/null 2>&1\n",
        "\n",
        "!python main/app/app.py --share --client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkqks7bO2Cye"
      },
      "source": [
        "# **Further customization üß∞**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1cxnr7qP2clf"
      },
      "outputs": [],
      "source": [
        "#@title **Connect or Disconnect to Drive ‚òÅ**\n",
        "import os\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "if os.path.exists(\"/content/drive\"):\n",
        "    print(\"üîó Disconnecting from drive...\")\n",
        "    try:\n",
        "        drive.flush_and_unmount()\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Completed!\", button_style=\"success\"))\n",
        "    except Exception as e:\n",
        "        raise ValueError(f'An error occurred during drive disconnection: {e}')\n",
        "else:\n",
        "    print('üîó Connecting to drive...')\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Completed!\", button_style=\"success\"))\n",
        "    except Exception as e:\n",
        "        raise ValueError(f'An error occurred during drive connection: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-pS4-MMA7L9X"
      },
      "outputs": [],
      "source": [
        "#@title **Start or Stop Backup üõ†**\n",
        "import os\n",
        "import time\n",
        "import threading\n",
        "import subprocess\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "\n",
        "logs_folder, weights_folder, audios_folder = '/content/drive/MyDrive/model/logs', '/content/drive/MyDrive/model/weights', '/content/drive/MyDrive/audios'\n",
        "\n",
        "#@markdown **If no box is checked, the connection will be stopped for that part**\n",
        "start_model_backup = False #@param {\"type\":\"boolean\"}\n",
        "start_audio_backup = False #@param {\"type\":\"boolean\"}\n",
        "#@markdown **Synchronization will sync the backup folders; if a file is deleted from the source folder, it will also be deleted from the backup folder**\n",
        "synchronize_folders = False #@param {\"type\":\"boolean\"}\n",
        "\n",
        "\n",
        "class Channel:\n",
        "    def __init__(self, source, destination, sync_deletions=False, every=60, exclude = None):\n",
        "        self.source = source\n",
        "        self.destination = destination\n",
        "        self.event = threading.Event()\n",
        "        self.syncing_thread = threading.Thread(target=self._sync, args=())\n",
        "        self.sync_deletions = sync_deletions\n",
        "        self.every = every\n",
        "\n",
        "        if not exclude: exclude = []\n",
        "        if isinstance(exclude, str): exclude = [exclude]\n",
        "\n",
        "        self.exclude = exclude\n",
        "        self.command = ['rsync', '-aP']\n",
        "\n",
        "    def alive(self):\n",
        "        if self.syncing_thread.is_alive(): return True\n",
        "        else: return False\n",
        "\n",
        "    def _sync(self):\n",
        "        command = self.command\n",
        "\n",
        "        for exclusion in self.exclude:\n",
        "            command.append(f'--exclude={exclusion}')\n",
        "\n",
        "        command.extend([f'{self.source}/', f'{self.destination}/'])\n",
        "\n",
        "        if self.sync_deletions: command.append('--delete')\n",
        "\n",
        "        while not self.event.is_set():\n",
        "            subprocess.run(command)\n",
        "            time.sleep(self.every)\n",
        "\n",
        "    def copy(self):\n",
        "        command = self.command\n",
        "\n",
        "        for exclusion in self.exclude:\n",
        "            command.append(f'--exclude={exclusion}')\n",
        "\n",
        "        command.extend([f'{self.source}/', f'{self.destination}/'])\n",
        "\n",
        "        if self.sync_deletions: command.append('--delete')\n",
        "        subprocess.run(command)\n",
        "\n",
        "        return True\n",
        "\n",
        "    def start(self):\n",
        "        if self.syncing_thread.is_alive():\n",
        "            self.event.set()\n",
        "            self.syncing_thread.join()\n",
        "\n",
        "        if self.event.is_set(): self.event.clear()\n",
        "        if self.syncing_thread._started.is_set(): self.syncing_thread = threading.Thread(target=self._sync, args=())\n",
        "\n",
        "        self.syncing_thread.start()\n",
        "        return self.alive()\n",
        "\n",
        "    def stop(self):\n",
        "        if self.alive():\n",
        "            self.event.set()\n",
        "            self.syncing_thread.join()\n",
        "\n",
        "            while self.alive():\n",
        "                if not self.alive(): break\n",
        "\n",
        "        return not self.alive()\n",
        "\n",
        "if not \"logs_backup\" in locals(): logs_backup = Channel(\"/content/Vietnamese_RVC/assets/logs\", logs_folder, sync_deletions=synchronize_folders, every=40, exclude=\"mute\")\n",
        "if not \"weights_backup\" in locals(): weights_backup = Channel(\"/content/Vietnamese_RVC/assets/weights\", weights_folder, sync_deletions=synchronize_folders, every=40)\n",
        "if not \"audio_backup\" in locals(): audio_backup = Channel(\"/content/Vietnamese_RVC/audios\", audios_folder, sync_deletions=synchronize_folders, every=40)\n",
        "\n",
        "logs_backup.stop(); weights_backup.stop(); audio_backup.stop()\n",
        "\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "    if start_model_backup:\n",
        "        if not os.path.exists(logs_folder): os.makedirs(logs_folder)\n",
        "        if not os.path.exists(weights_folder): os.makedirs(weights_folder)\n",
        "\n",
        "        logs_backup.start(); weights_backup.start()\n",
        "    else: logs_backup.stop(); weights_backup.stop()\n",
        "\n",
        "    if start_audio_backup:\n",
        "        if not os.path.exists(audios_folder): os.makedirs(audios_folder)\n",
        "        audio_backup.start()\n",
        "    else: audio_backup.stop()\n",
        "else:\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "    except Exception as e:\n",
        "        raise ValueError(f'An error occurred during drive connection: {e}')\n",
        "\n",
        "    if start_model_backup:\n",
        "        if not os.path.exists(logs_folder): os.makedirs(logs_folder)\n",
        "        if not os.path.exists(weights_folder): os.makedirs(weights_folder)\n",
        "\n",
        "        logs_backup.start(); weights_backup.start()\n",
        "    else: logs_backup.stop(); weights_backup.stop()\n",
        "\n",
        "    if start_audio_backup:\n",
        "        if not os.path.exists(audios_folder): os.makedirs(audios_folder)\n",
        "        audio_backup.start()\n",
        "    else: audio_backup.stop()\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Completed!\", button_style=\"success\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2VfuHALUuW_B"
      },
      "outputs": [],
      "source": [
        "#@title **‚ôªÔ∏è Start Garbage Collection**\n",
        "import os\n",
        "import time\n",
        "import threading\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import auth, drive\n",
        "from IPython.display import clear_output\n",
        "\n",
        "try:\n",
        "    from googleapiclient.discovery import build\n",
        "except:\n",
        "    os.system(\"pip install google-api-python-client\")\n",
        "    from googleapiclient.discovery import build\n",
        "\n",
        "class Clean:\n",
        "    def __init__(self, every=60):\n",
        "        self.service = build('drive', 'v3')\n",
        "        self.every = every\n",
        "        self.trash_cleanup_thread = None\n",
        "\n",
        "    def delete(self):\n",
        "        page_token = None\n",
        "\n",
        "        while 1:\n",
        "            response = self.service.files().list(q=\"trashed=true\", spaces='drive', fields=\"nextPageToken, files(id, name)\", pageToken=page_token).execute()\n",
        "\n",
        "            for file in response.get('files', []):\n",
        "                if file['name'].startswith(\"G_\") and file['name'].endswith(\".pth\") or file['name'].startswith(\"D_\") and file['name'].endswith(\".pth\"):\n",
        "                    try:\n",
        "                        self.service.files().delete(fileId=file['id']).execute()\n",
        "                    except Exception as e:\n",
        "                        raise RuntimeError(e)\n",
        "\n",
        "            page_token = response.get('nextPageToken', None)\n",
        "            if page_token is None: break\n",
        "\n",
        "    def clean(self):\n",
        "        while 1:\n",
        "            self.delete()\n",
        "            time.sleep(self.every)\n",
        "\n",
        "    def start(self):\n",
        "        self.trash_cleanup_thread = threading.Thread(target=self.clean)\n",
        "        self.trash_cleanup_thread.daemon = True\n",
        "        self.trash_cleanup_thread.start()\n",
        "\n",
        "    def stop(self):\n",
        "        if self.trash_cleanup_thread: self.trash_cleanup_thread.join()\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "#@markdown **Use during training to clean up D_, G_ files in Google Drive trash**\n",
        "start_garbage_collection = False #@param {\"type\":\"boolean\"}\n",
        "\n",
        "if start_garbage_collection:\n",
        "    if os.path.exists('/content/drive/MyDrive'):\n",
        "        auth.authenticate_user()\n",
        "    else:\n",
        "        try:\n",
        "            drive.mount('/content/drive')\n",
        "        except Exception as e:\n",
        "            raise ValueError(f'An error occurred during drive connection: {e}')\n",
        "\n",
        "        auth.authenticate_user()\n",
        "    Clean(every=40).start()\n",
        "else: Clean().stop()\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Completed!\", button_style=\"success\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xbcVxSFMDOV4"
      },
      "outputs": [],
      "source": [
        "#@title **Load Backup Data from Drive üìÇ**\n",
        "import os\n",
        "import shutil\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "logs_folder, weights_folder, audios_folder ='/content/drive/MyDrive/model/logs', '/content/drive/MyDrive/model/weights', '/content/drive/MyDrive/audios'\n",
        "\n",
        "#@markdown **Load trained models to continue training**\n",
        "load_models = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **Load backed up audios to continue using**\n",
        "load_audios = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "if os.path.exists(\"/content/drive/MyDrive\"):\n",
        "  if load_models:\n",
        "    if len(os.listdir(logs_folder)) < 1 or len(os.listdir(weights_folder)) < 1: print(\"No Data Found\")\n",
        "    else:\n",
        "      if os.path.exists(\"/content/drive/MyDrive/model\"):\n",
        "        shutil.copytree(logs_folder, \"/content/main_core/assets/logs\", dirs_exist_ok=True)\n",
        "        shutil.copytree(weights_folder, \"/content/main_core/assets/weights\", dirs_exist_ok=True)\n",
        "\n",
        "        clear_output()\n",
        "      else: print(\"No model data found\")\n",
        "  if load_audios:\n",
        "    if len(os.listdir(audios_folder)) < 1: print(\"No Data Found\")\n",
        "    else:\n",
        "      if os.path.exists(\"/content/drive/MyDrive/audios\"):\n",
        "        shutil.copytree(audios_folder, \"/content/main_core/audios\", dirs_exist_ok=True)\n",
        "        clear_output()\n",
        "      else: print(\"No audio data found\")\n",
        "else: print(\"Google Drive is not connected\")\n",
        "\n",
        "display(Button(description=\"\\u2714 Completed!\", button_style=\"success\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Download üì©**"
      ],
      "metadata": {
        "id": "vk026-j6Cm_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **üîé Search for Models**\n",
        "import json\n",
        "import codecs\n",
        "import requests\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def fetch_models_data(search):\n",
        "    all_table_data = []\n",
        "    page = 1\n",
        "\n",
        "    while 1:\n",
        "        try:\n",
        "            response = requests.post(url=codecs.decode(\"uggcf://ibvpr-zbqryf.pbz/srgpu_qngn.cuc\", \"rot13\"), data={\"page\": page, \"search\": search})\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                table_data = response.json().get(\"table\", \"\")\n",
        "                if not table_data.strip(): break\n",
        "                all_table_data.append(table_data)\n",
        "                page += 1\n",
        "            else: raise Exception(f\"An error occurred, Error code: {response.status_code}\")\n",
        "        except json.JSONDecodeError:\n",
        "            raise Exception(\"An error occurred, unable to parse the response.\")\n",
        "        except requests.RequestException as e:\n",
        "            raise Exception(f\"Failed to send request: {e}\")\n",
        "    return all_table_data\n",
        "\n",
        "def search_models(name):\n",
        "    if not name: raise NameError(\"Please enter a model name\")\n",
        "    tables = fetch_models_data(name)\n",
        "\n",
        "    if len(tables) == 0: print(\"No results found...\")\n",
        "    else:\n",
        "        for table in tables:\n",
        "            for row in BeautifulSoup(table, \"html.parser\").select(\"tr\"):\n",
        "                name_tag, url_tag = row.find(\"a\", {\"class\": \"fs-5\"}), row.find(\"a\", {\"class\": \"btn btn-sm fw-bold btn-light ms-0 p-1 ps-2 pe-2\"})\n",
        "                if name_tag and url_tag:\n",
        "                    name = name_tag.text.replace(\".onnx\", \"\").replace(\".pth\", \"\").replace(\".index\", \"\").replace(\".zip\", \"\").replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace('\"', \"\").replace(\"'\", \"\").replace(\"|\", \"_\").replace(\"-_-\", \"_\").replace(\"_-_\", \"_\").replace(\"-\", \"_\").replace(\"---\", \"_\").replace(\"___\", \"_\").strip()\n",
        "                    url = url_tag[\"href\"].replace(\"https://easyaivooice.com/run?url=\", \"\")\n",
        "                    if \"huggingface\" in url: print(f\"{name}: {url}\")\n",
        "\n",
        "#@markdown **Search for model links**\n",
        "model_name = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Name of the model to search for\"}\n",
        "\n",
        "search_models(model_name)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "49Mc9pnY9kdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **üì© Download Model**\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "#@markdown **Supports links from huggingface.co / drive.google.com / mega.nz / mediafire.com**\n",
        "\n",
        "model_name = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Model name\"}\n",
        "model_link = \"\" # @param {\"type\":\"string\",\"placeholder\":\"https://huggingface.co//...\"}\n",
        "\n",
        "if not model_link:\n",
        "    uploaded = files.upload()\n",
        "    args = f'from main.app.core.process import save_drop_model; save_drop_model(\\\\\"{[list(uploaded.keys())[0]]}\\\\\")'\n",
        "    !python3 -c \"$args\"\n",
        "else:\n",
        "    args = f'from main.app.core.downloads import download_model; download_model(\\\\\"{model_link}\\\\\", \\\\\"{model_name}\\\\\")'\n",
        "    !python3 -c \"$args\"\n",
        "\n",
        "clear_output()\n",
        "display(Button(description=\"\\u2714 Completed!!\", button_style=\"success\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FYEQawebCzZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üßæ **Download Pre-trained Models**\n",
        "#@markdown **Run this cell to select a model and its sampling rate for download**\n",
        "import os\n",
        "import shutil\n",
        "import codecs\n",
        "import requests\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "from main.tools import huggingface\n",
        "\n",
        "def fetch_pretrained_data():\n",
        "    response = requests.get(codecs.decode(\"uggcf://uhttvatsnpr.pb/NauC/Ivrganzrfr-EIP-Cebwrpg/erfbyir/znva/wfba/phfgbz_cergenvarq.wfba\", \"rot13\"))\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "model_list = list(fetch_pretrained_data().keys())\n",
        "\n",
        "for m in model_list:\n",
        "    print(f\"{model_list.index(m)}. {m}\")\n",
        "\n",
        "while 1:\n",
        "    try:\n",
        "        model_index = int(input(\"Enter the model number: \"))\n",
        "        if 0 <= model_index < len(model_list):\n",
        "            selected_model = model_list[model_index]\n",
        "            clear_output()\n",
        "            print(f\"You selected model: {selected_model}\")\n",
        "            break\n",
        "        else: print(\"Invalid number. Please enter again.\")\n",
        "    except ValueError:\n",
        "        print(\"Please enter an integer.\")\n",
        "    except IndexError:\n",
        "        print(\"Number out of range. Please enter again.\")\n",
        "\n",
        "model_sr_list = list(fetch_pretrained_data()[selected_model].keys())\n",
        "\n",
        "if len(model_sr_list) == 1: selected_sr = model_sr_list[0]\n",
        "else:\n",
        "    for sr in model_sr_list:\n",
        "        print(f\"{model_sr_list.index(sr)}. {sr}\")\n",
        "\n",
        "    while 1:\n",
        "        try:\n",
        "            model_sr_index = int(input(\"Enter the sampling rate number: \"))\n",
        "            if 0 <= model_sr_index < len(model_sr_list):\n",
        "                selected_sr = model_sr_list[model_sr_index]\n",
        "                print(f\"You selected sampling rate: {selected_sr}\")\n",
        "                clear_output()\n",
        "                break\n",
        "            else: print(\"Invalid number. Please enter again.\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter an integer.\")\n",
        "        except IndexError:\n",
        "            print(\"Number out of range. Please enter again.\")\n",
        "\n",
        "paths = fetch_pretrained_data()[selected_model][selected_sr]\n",
        "pretraineds_custom_path = os.path.join(\"assets\", \"models\", \"pretrained_custom\")\n",
        "\n",
        "if not os.path.exists(pretraineds_custom_path): os.makedirs(pretraineds_custom_path, exist_ok=True)\n",
        "url = codecs.decode(\"uggcf://uhttvatsnpr.pb/NauC/Ivrganzrfr-EIP-Cebwrpg/erfbyir/znva/cergenvarq_phfgbz/\", \"rot13\") + paths\n",
        "\n",
        "file = huggingface.HF_download_file(url.replace(\"/blob/\", \"/resolve/\").replace(\"?download=true\", \"\").strip(), os.path.join(pretraineds_custom_path, paths))\n",
        "if file.endswith(\".zip\"):\n",
        "    shutil.unpack_archive(file, pretraineds_custom_path)\n",
        "    os.remove(file)\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Completed!\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1a52Dg5VHqFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üì• **Download Pre-trained Models**\n",
        "import os\n",
        "import json\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/main_core\n",
        "\n",
        "#@markdown **Enter the pre-trained model URLs to download**\n",
        "pretrained_D = \"\" # @param {\"type\":\"string\",\"placeholder\":\"https://huggingface.co//...\"}\n",
        "pretrained_G = \"\" # @param {\"type\":\"string\",\"placeholder\":\"https://huggingface.co//...\"}\n",
        "\n",
        "download_url = \"Download from the link\" if json.load(open(os.path.join(\"main\", \"configs\", \"config.json\"), \"r\")).get(\"language\", \"vi-VN\") == \"en-US\" else \"Download from the link\"\n",
        "\n",
        "args = f'from main.app.core.downloads import download_pretrained_model; download_pretrained_model(\\\\\"{download_url}\\\\\", \\\\\"{pretrained_D}\\\\\", \\\\\"{pretrained_G}\\\\\")'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Completed!\", button_style=\"success\")#@title üì• **Download Pre-trained Models**\n",
        "import os\n",
        "import json\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "#@markdown **Enter the pre-trained model URLs to download**\n",
        "pretrained_D = \"\" # @param {\"type\":\"string\",\"placeholder\":\"https://huggingface.co//...\"}\n",
        "pretrained_G = \"\" # @param {\"type\":\"string\",\"placeholder\":\"https://huggingface.co//...\"}\n",
        "\n",
        "download_url = \"Download from the link\" if json.load(open(os.path.join(\"main\", \"configs\", \"config.json\"), \"r\")).get(\"language\", \"vi-VN\") == \"en-US\" else \"Download from the link\"\n",
        "\n",
        "args = f'from main.app.core.downloads import download_pretrained_model; download_pretrained_model(\\\\\"{download_url}\\\\\", \\\\\"{pretrained_D}\\\\\", \\\\\"{pretrained_G}\\\\\")'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Completed!\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QuFUjo-zIDWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference**"
      ],
      "metadata": {
        "id": "QxkQHawDuqDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Music Separation**\n",
        "import os\n",
        "import re\n",
        "import yt_dlp\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from urllib.parse import urlparse\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "%cd /content/Vietnamese_RVC\n",
        "\n",
        "def download_url(url):\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\")\n",
        "        ydl_opts = {\"format\": \"bestaudio/best\", \"postprocessors\": [{\"key\": \"FFmpegExtractAudio\", \"preferredcodec\": \"wav\", \"preferredquality\": \"192\"}], \"quiet\": True, \"no_warnings\": True, \"noplaylist\": True, \"verbose\": False}\n",
        "\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            audio_output = os.path.join(\"audios\", re.sub(r'\\s+', '-', re.sub(r'[^\\w\\s\\u4e00-\\u9fff\\uac00-\\ud7af\\u0400-\\u04FF\\u1100-\\u11FF]', '', ydl.extract_info(url, download=False).get('title', 'video')).strip()))\n",
        "            if os.path.exists(audio_output): shutil.rmtree(audio_output, ignore_errors=True)\n",
        "\n",
        "            ydl_opts['outtmpl'] = audio_output\n",
        "\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            audio_output += \".wav\"\n",
        "            ydl.download([url])\n",
        "\n",
        "        return audio_output\n",
        "\n",
        "def is_url(path):\n",
        "    try:\n",
        "        result = urlparse(path)\n",
        "        return all([result.scheme, result.netloc])\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "#@markdown **Options for separating stems and reverb**\n",
        "separate_stems = False # @param {\"type\":\"boolean\"}\n",
        "separate_reverb = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **Input path (can be a URL or file path) and output audio format**\n",
        "path = \"\" #@param {\"type\":\"string\", \"placeholder\":\"Enter path to audio file or audio URL\"}\n",
        "audio_format = \"wav\" #@param [\"wav\", \"mp3\", \"flac\", \"ogg\", \"opus\", \"m4a\", \"mp4\", \"aac\", \"alac\", \"wma\", \"aiff\", \"webm\", \"ac3\"]\n",
        "#@markdown **Music separation model options, overlap level, and segment size**\n",
        "separation_model = \"Voc_FT\" #@param [\"Main_340\", \"Main_390\", \"Main_406\", \"Main_427\", \"Main_438\", \"Inst_full_292\", \"Inst_HQ_1\", \"Inst_HQ_2\", \"Inst_HQ_3\", \"Inst_HQ_4\", \"Inst_HQ_5\", \"Kim_Vocal_1\", \"Kim_Vocal_2\", \"Kim_Inst\", \"Inst_187_beta\", \"Inst_82_beta\", \"Inst_90_beta\", \"Voc_FT\", \"Crowd_HQ\", \"Inst_1\", \"Inst_2\", \"Inst_3\", \"MDXNET_1_9703\", \"MDXNET_2_9682\", \"MDXNET_3_9662\", \"Inst_Main\", \"MDXNET_Main\", \"MDXNET_9482\", \"HT-Normal\", \"HT-Tuned\", \"HD_MMI\",  \"HT_6S\"]\n",
        "overlap = \"0.25\" # @param [\"0.25\", \"0.5\", \"0.75\", \"0.99\"]\n",
        "segment_size = 336 # @param {\"type\":\"slider\",\"min\":32,\"max\":2048,\"step\":8}\n",
        "\n",
        "if not path:\n",
        "    uploaded = files.upload()\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    input_path = os.path.join(\"audios\", os.path.basename(filename).replace(' ', '_').replace('(', '').replace(')', '').replace('{', '').replace('}', ''))\n",
        "    shutil.move(filename, input_path)\n",
        "else: input_path = download_url(path) if is_url(path) else path\n",
        "\n",
        "args = f'from main.app.core.separate import separate_music; separate_music(\\\\\"{input_path}\\\\\", \\\\\"audios\\\\\", \\\\\"{audio_format}\\\\\", \\\\\"{separation_model}\\\\\", \\\\\"MDX-Version-2\\\\\", \\\\\"MDX-Reverb\\\\\", \\\\\"Lite\\\\\", 48000, 2, 1, {overlap}, 5, 1024, 512, {segment_size}, 0.2, False, True, False, False, {separate_stems}, {separate_reverb})'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "clear_output()\n",
        "print(f\"Your output files are located in: /content/Vietnamese_RVC/audios/{os.path.splitext(os.path.basename(input_path))[0]}\")\n",
        "display(Button(description=\"\\u2714 Complete!\", button_style=\"success\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1R7mSj8avRF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üéµ **Audio Conversion** üéµ\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "%cd /content/main_core\n",
        "\n",
        "def convert_audio(clean, autotune, use_audio, use_original, convert_backing, not_merge_backing, merge_instrument, pitch, clean_strength, model, index, index_rate, input, output, format, method, hybrid_method, hop_length, embedders, custom_embedders, resample_sr, filter_radius, volume_envelope, protect, split_audio, f0_autotune_strength, input_audio_name, checkpointing, onnx_f0_mode, formant_shifting, formant_qfrency, formant_timbre, f0_file, embedders_mode):\n",
        "    args = f'from main.app.core.inference import convert_audio; convert_audio({clean}, {autotune}, {use_audio}, {use_original}, {convert_backing}, {not_merge_backing}, {merge_instrument}, {pitch}, {clean_strength}, \\\\\"{model}\\\\\", \\\\\"{index}\\\\\", {index_rate}, \\\\\"{input}\\\\\", \\\\\"{output}\\\\\", \\\\\"{format}\\\\\", \\\\\"{method}\\\\\", \\\\\"{hybrid_method}\\\\\", {hop_length}, \\\\\"{embedders}\\\\\", \\\\\"{custom_embedders}\\\\\", {resample_sr}, {filter_radius}, {volume_envelope}, {protect}, {split_audio}, {f0_autotune_strength}, \\\\\"{input_audio_name}\\\\\", {checkpointing}, {onnx_f0_mode}, {formant_shifting}, {formant_qfrency}, {formant_timbre}, \\\\\"{f0_file}\\\\\", \\\\\"{embedders_mode}\\\\\", False, 0)'\n",
        "    !python3 -c \"$args\"\n",
        "\n",
        "def get_audio_file(output_audio, label):\n",
        "    matching_files = [f for f in os.listdir(output_audio) if label in f]\n",
        "\n",
        "    if not matching_files: raise FileNotFoundError(\"No backing track found!\")\n",
        "    return os.path.join(output_audio, matching_files[0])\n",
        "\n",
        "def convert_selection(clean, autotune, use_audio, use_original, convert_backing, not_merge_backing, merge_instrument, pitch, clean_strength, model, index, index_rate, input, output, format, method, hybrid_method, hop_length, embedders, custom_embedders, resample_sr, filter_radius, volume_envelope, protect, split_audio, f0_autotune_strength, checkpointing, onnx_f0_mode, formant_shifting, formant_qfrency, formant_timbre, f0_file, embedders_mode):\n",
        "    if use_audio:\n",
        "        choice = [f for f in os.listdir(\"audios\") if os.path.isdir(os.path.join(\"audios\", f))]\n",
        "\n",
        "        if len(choice) == 0: raise FileNotFoundError(\"No separated tracks found!\")\n",
        "        elif len(choice) == 1:\n",
        "            choice_audio = choice[0]\n",
        "            convert_audio(clean, autotune, use_audio, use_original, convert_backing, not_merge_backing, False, pitch, clean_strength, model, index, index_rate, None, None, format, method, hybrid_method, hop_length, embedders, custom_embedders, resample_sr, filter_radius, volume_envelope, protect, split_audio, f0_autotune_strength, choice_audio, checkpointing, onnx_f0_mode, formant_shifting, formant_qfrency, formant_timbre, f0_file, embedders_mode)\n",
        "        else:\n",
        "            print(\"Found more than 1 separated track, please select one to proceed with conversion!\")\n",
        "            for c in choice:\n",
        "                print(f\"{choice.index(c)}. {c}\")\n",
        "\n",
        "            while 1:\n",
        "                try:\n",
        "                    choice_select = int(input(\"Enter the number of the separated track: \"))\n",
        "\n",
        "                    if 0 <= choice_select < len(choice):\n",
        "                        choice_audio = choice[choice_select]\n",
        "                        print(f\"You selected the track: {choice_audio}\")\n",
        "                        break\n",
        "                    else: print(\"Invalid number. Please try again.\")\n",
        "                except ValueError:\n",
        "                    print(\"Please enter an integer.\")\n",
        "                except IndexError:\n",
        "                    print(\"Number out of range. Please try again.\")\n",
        "            convert_audio(clean, autotune, use_audio, use_original, convert_backing, not_merge_backing, False, pitch, clean_strength, model, index, index_rate, None, None, format, method, hybrid_method, hop_length, embedders, custom_embedders, resample_sr, filter_radius, volume_envelope, protect, split_audio, f0_autotune_strength, choice_audio, checkpointing, onnx_f0_mode, formant_shifting, formant_qfrency, formant_timbre, f0_file, embedders_mode)\n",
        "    else: convert_audio(clean, autotune, use_audio, use_original, convert_backing, not_merge_backing, False, pitch, clean_strength, model, index, index_rate, input, output, format, method, hybrid_method, hop_length, embedders, custom_embedders, resample_sr, filter_radius, volume_envelope, protect, split_audio, f0_autotune_strength, None, checkpointing, onnx_f0_mode, formant_shifting, formant_qfrency, formant_timbre, f0_file, embedders_mode)\n",
        "\n",
        "    if use_audio: output_path = f\"/content/Vietnamese_RVC/audios/{choice_audio}/Vocals+Backing.{format}\" if convert_backing else f\"/content/Vietnamese_RVC/audios/{choice_audio}/Convert_Vocals.{format}\"\n",
        "    return audio_effects(output_path, os.path.join(\"audios\", choice_audio, f\"Vocals+Instruments.{format}\") if merge_instrument else os.path.join(\"audios\", choice_audio, f\"{os.path.splitext(os.path.basename(output_path))[0]}_Effects.{format}\"), format, merge_instrument, get_audio_file(os.path.join(\"audios\", choice_audio), \"Instruments.\")) if use_audio else f\"/content/Vietnamese_RVC/audios/output.{format}\"\n",
        "\n",
        "def audio_effects(input_path, output_path, export_format, merge_instrument, audio_combination_input):\n",
        "    if not input_path or not os.path.exists(input_path) or os.path.isdir(input_path): raise FileNotFoundError(\"Invalid input file path!\")\n",
        "    if not output_path: raise ValueError(\"Invalid output file path!\")\n",
        "    output_dir = os.path.dirname(output_path) or output_path\n",
        "\n",
        "    if not os.path.exists(output_dir): os.makedirs(output_dir, exist_ok=True)\n",
        "    if os.path.exists(output_path): os.remove(output_path)\n",
        "\n",
        "    !python main/inference/audio_effects.py --input_path $input_path --output_path $output_path --reverb_room_size 0.15 --reverb_damping 0.7 --reverb_wet_level 0.2 --reverb_dry_level 0.8 --reverb_width 1.0 --reverb_freeze_mode False --export_format $export_format --reverb True --audio_combination $merge_instrument --audio_combination_input $audio_combination_input\n",
        "    return output_path\n",
        "\n",
        "def get_index(model):\n",
        "    return next((f for f in [os.path.join(root, name) for root, _, files in os.walk(os.path.join(\"assets\", \"logs\"), topdown=False) for name in files if name.endswith(\".index\") and \"trained\" not in name] if model.split(\".\")[0] in f), \"\")\n",
        "\n",
        "#@markdown **Options for using previously separated audio tracks**\n",
        "use_separated_audio = False #@param {\"type\":\"boolean\"}\n",
        "convert_backing_track = False #@param {\"type\":\"boolean\"}\n",
        "merge_with_instrumental = False #@param {\"type\":\"boolean\"}\n",
        "#@markdown **Model options: Pitch and Index**\n",
        "model_name = \"\" #@param {\"type\":\"string\",\"placeholder\":\"Model name\"}\n",
        "pitch_shift = 0 #@param {\"type\":\"slider\",\"min\":-20,\"max\":20,\"step\":1}\n",
        "index_influence = 0.5 #@param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.01}\n",
        "#@markdown **Input file and output format options**\n",
        "input_file_path = \"\" #@param {\"type\":\"string\",\"placeholder\":\"Audio file path\"}\n",
        "output_file_format = \"wav\" #@param [\"wav\", \"mp3\", \"flac\", \"ogg\", \"opus\", \"m4a\", \"mp4\", \"aac\", \"alac\", \"wma\", \"aiff\", \"webm\", \"ac3\"]\n",
        "#@markdown **Feature extraction options, hop length, voice protection, and automatic pitch adjustment for higher quality**\n",
        "extraction_method = \"rmvpe\" #@param [\"pm-ac\", \"pm-cc\", \"pm-shs\", \"dio\", \"mangio-crepe-tiny\", \"mangio-crepe-small\", \"mangio-crepe-medium\", \"mangio-crepe-large\", \"mangio-crepe-full\", \"crepe-tiny\", \"crepe-small\", \"crepe-medium\", \"crepe-large\", \"crepe-full\", \"fcpe\", \"fcpe-legacy\", \"rmvpe\", \"rmvpe-legacy\", \"harvest\", \"yin\", \"pyin\", \"swipe\", \"piptrack\", \"fcn\", \"djcm\"]\n",
        "hop_length = 64 # @param {\"type\":\"slider\",\"min\":64,\"max\":512,\"step\":1}\n",
        "voice_protection = 0.5 #@param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.1}\n",
        "#@markdown **Audio splitting and automatic pitch options**\n",
        "split_audio = False #@param {\"type\":\"boolean\"}\n",
        "\n",
        "if model_name:\n",
        "    if not model_name.endswith((\".pth\", \".onnx\")): model_name = model_name + \".pth\"\n",
        "    model_path = os.path.join(\"assets\", \"weights\", model_name)\n",
        "    index_path = get_index(model_name.split(\"_\")[0])\n",
        "else:\n",
        "    model_name = sorted(list(model for model in os.listdir(os.path.join(\"assets\", \"weights\")) if model.endswith((\".pth\", \".onnx\")) and not model.startswith(\"G_\") and not model.startswith(\"D_\")))\n",
        "    indexpath = sorted([os.path.join(root, name) for root, _, files in os.walk(os.path.join(\"assets\", \"logs\"), topdown=False) for name in files if name.endswith(\".index\")])\n",
        "\n",
        "    if len(model_name) < 1: raise ValueError(\"Please provide a model to proceed with conversion!\")\n",
        "    elif len(model_name) == 1:\n",
        "        model_path = os.path.join(\"assets\", \"weights\", model_name[0])\n",
        "        index_path = get_index(os.path.basename(model_name[0])[0])\n",
        "    else:\n",
        "        print(\"Found more than 1 model, please enter the model number to proceed with conversion!\")\n",
        "        for m in model_name:\n",
        "            print(f\"{model_name.index(m)}. {m}\")\n",
        "\n",
        "        while 1:\n",
        "            try:\n",
        "                model_index = int(input(\"Enter the model number: \"))\n",
        "                if model_index < len(model_name):\n",
        "                    selected_model = model_name[model_index]\n",
        "                    print(f\"You selected the model: {selected_model}\")\n",
        "                    break\n",
        "                else: print(\"Invalid number. Please try again.\")\n",
        "            except ValueError:\n",
        "                print(\"Please enter an integer.\")\n",
        "            except IndexError:\n",
        "                print(\"Number out of range. Please try again.\")\n",
        "\n",
        "        model_path = os.path.join(\"assets\", \"weights\", selected_model)\n",
        "        index_path = get_index(os.path.basename(selected_model).split(\"_\")[0])\n",
        "\n",
        "if not index_path: print(\"No index found!\")\n",
        "\n",
        "if not input_file_path and not (use_separated_audio or convert_backing_track or merge_with_instrumental):\n",
        "    uploaded = files.upload()\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    input_path = os.path.join(\"audios\", os.path.basename(filename).replace(' ', '_').replace('(', '').replace(')', '').replace('{', '').replace('}', ''))\n",
        "    shutil.move(filename, input_path)\n",
        "else: input_path = input_file_path\n",
        "\n",
        "output_files = convert_selection(False, False, (use_separated_audio or convert_backing_track or merge_with_instrumental), use_separated_audio, convert_backing_track, False, merge_with_instrumental, pitch_shift, 0.7, model_path, index_path, index_influence, input_path, os.path.join(\"audios\", \"output.wav\"), output_file_format, extraction_method, None, hop_length, \"hubert_base\", None, 0, 3, 1, voice_protection, split_audio, 1, False, False, False, 0, 0, \"\", \"fairseq\")\n",
        "clear_output()\n",
        "\n",
        "print(f\"Your output file is: {output_files}\")\n",
        "display(Button(description=\"\\u2714 Complete!\", button_style=\"success\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aQ8LqaeGLDYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title üéµ **Text-to-Speech Conversion** üéµ\n",
        "import os\n",
        "import zipfile\n",
        "import xml.etree.ElementTree\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "%cd /content/main_core\n",
        "\n",
        "def get_index(model):\n",
        "    return next((f for f in [os.path.join(root, name) for root, _, files in os.walk(os.path.join(\"assets\", \"logs\"), topdown=False) for name in files if name.endswith(\".index\") and \"trained\" not in name] if model.split(\".\")[0] in f), \"\")\n",
        "\n",
        "def read_docx_text(path):\n",
        "    with zipfile.ZipFile(path) as docx:\n",
        "        with docx.open(\"word/document.xml\") as document_xml:\n",
        "            xml_content = document_xml.read()\n",
        "\n",
        "    WORD_NAMESPACE = '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}'\n",
        "\n",
        "    paragraphs = []\n",
        "    for paragraph in xml.etree.ElementTree.XML(xml_content).iter(WORD_NAMESPACE + 'p'):\n",
        "        texts = [node.text for node in paragraph.iter(WORD_NAMESPACE + 't') if node.text]\n",
        "        if texts: paragraphs.append(''.join(texts))\n",
        "\n",
        "    return '\\n'.join(paragraphs)\n",
        "\n",
        "def process_input(file_path):\n",
        "    if file_path.endswith(\".srt\"): file_contents = \"\"\n",
        "    elif file_path.endswith(\".docx\"): file_contents = read_docx_text(file_path)\n",
        "    else:\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "                file_contents = file.read()\n",
        "        except Exception as e:\n",
        "            file_contents = \"\"\n",
        "\n",
        "    return file_contents\n",
        "\n",
        "#@markdown **Text to read and voice/speech rate options**\n",
        "text_input = \"\" # @param {\"type\":\"string\", \"placeholder\":\"Text to read\"}\n",
        "voice = \"jv-ID-DimasNeural\" # @param [\"af-ZA-AdriNeural\", \"af-ZA-WillemNeural\", \"sq-AL-AnilaNeural\", \"sq-AL-IlirNeural\", \"am-ET-AmehaNeural\", \"am-ET-MekdesNeural\", \"ar-DZ-AminaNeural\", \"ar-DZ-IsmaelNeural\", \"ar-BH-AliNeural\", \"ar-BH-LailaNeural\", \"ar-EG-SalmaNeural\", \"ar-EG-ShakirNeural\", \"ar-IQ-BasselNeural\", \"ar-IQ-RanaNeural\", \"ar-JO-SanaNeural\", \"ar-JO-TaimNeural\", \"ar-KW-FahedNeural\", \"ar-KW-NouraNeural\", \"ar-LB-LaylaNeural\", \"ar-LB-RamiNeural\", \"ar-LY-ImanNeural\", \"ar-LY-OmarNeural\", \"ar-MA-JamalNeural\", \"ar-MA-MounaNeural\", \"ar-OM-AbdullahNeural\", \"ar-OM-AyshaNeural\", \"ar-QA-AmalNeural\", \"ar-QA-MoazNeural\", \"ar-SA-HamedNeural\", \"ar-SA-ZariyahNeural\", \"ar-SY-AmanyNeural\", \"ar-SY-LaithNeural\", \"ar-TN-HediNeural\", \"ar-TN-ReemNeural\", \"ar-AE-FatimaNeural\", \"ar-AE-HamdanNeural\", \"ar-YE-MaryamNeural\", \"ar-YE-SalehNeural\", \"az-AZ-BabekNeural\", \"az-AZ-BanuNeural\", \"bn-BD-NabanitaNeural\", \"bn-BD-PradeepNeural\", \"bn-IN-BashkarNeural\", \"bn-IN-TanishaaNeural\", \"bs-BA-GoranNeural\", \"bs-BA-VesnaNeural\", \"bg-BG-BorislavNeural\", \"bg-BG-KalinaNeural\", \"my-MM-NilarNeural\", \"my-MM-ThihaNeural\", \"ca-ES-EnricNeural\", \"ca-ES-JoanaNeural\", \"zh-HK-HiuGaaiNeural\", \"zh-HK-HiuMaanNeural\", \"zh-HK-WanLungNeural\", \"zh-CN-XiaoxiaoNeural\", \"zh-CN-XiaoyiNeural\", \"zh-CN-YunjianNeural\", \"zh-CN-YunxiNeural\", \"zh-CN-YunxiaNeural\", \"zh-CN-YunyangNeural\", \"zh-CN-liaoning-XiaobeiNeural\", \"zh-TW-HsiaoChenNeural\", \"zh-TW-YunJheNeural\", \"zh-TW-HsiaoYuNeural\", \"zh-CN-shaanxi-XiaoniNeural\", \"hr-HR-GabrijelaNeural\", \"hr-HR-SreckoNeural\", \"cs-CZ-AntoninNeural\", \"cs-CZ-VlastaNeural\", \"da-DK-ChristelNeural\", \"da-DK-JeppeNeural\", \"nl-BE-ArnaudNeural\", \"nl-BE-DenaNeural\", \"nl-NL-ColetteNeural\", \"nl-NL-FennaNeural\", \"nl-NL-MaartenNeural\", \"en-AU-NatashaNeural\", \"en-AU-WilliamNeural\", \"en-CA-ClaraNeural\", \"en-CA-LiamNeural\", \"en-HK-SamNeural\", \"en-HK-YanNeural\", \"en-IN-NeerjaExpressiveNeural\", \"en-IN-NeerjaNeural\", \"en-IN-PrabhatNeural\", \"en-IE-ConnorNeural\", \"en-IE-EmilyNeural\", \"en-KE-AsiliaNeural\", \"en-KE-ChilembaNeural\", \"en-NZ-MitchellNeural\", \"en-NZ-MollyNeural\", \"en-NG-AbeoNeural\", \"en-NG-EzinneNeural\", \"en-PH-JamesNeural\", \"en-PH-RosaNeural\", \"en-SG-LunaNeural\", \"en-SG-WayneNeural\", \"en-ZA-LeahNeural\", \"en-ZA-LukeNeural\", \"en-TZ-ElimuNeural\", \"en-TZ-ImaniNeural\", \"en-GB-LibbyNeural\", \"en-GB-MaisieNeural\", \"en-GB-RyanNeural\", \"en-GB-SoniaNeural\", \"en-GB-ThomasNeural\", \"en-US-AvaMultilingualNeural\", \"en-US-AndrewMultilingualNeural\", \"en-US-EmmaMultilingualNeural\", \"en-US-BrianMultilingualNeural\", \"en-US-AvaNeural\", \"en-US-AndrewNeural\", \"en-US-EmmaNeural\", \"en-US-BrianNeural\", \"en-US-AnaNeural\", \"en-US-AriaNeural\", \"en-US-ChristopherNeural\", \"en-US-EricNeural\", \"en-US-GuyNeural\", \"en-US-JennyNeural\", \"en-US-MichelleNeural\", \"en-US-RogerNeural\", \"en-US-SteffanNeural\", \"et-EE-AnuNeural\", \"et-EE-KertNeural\", \"fil-PH-AngeloNeural\", \"fil-PH-BlessicaNeural\", \"fi-FI-HarriNeural\", \"fi-FI-NooraNeural\", \"fr-BE-CharlineNeural\", \"fr-BE-GerardNeural\", \"fr-CA-ThierryNeural\", \"fr-CA-AntoineNeural\", \"fr-CA-JeanNeural\", \"fr-CA-SylvieNeural\", \"fr-FR-VivienneMultilingualNeural\", \"fr-FR-RemyMultilingualNeural\", \"fr-FR-DeniseNeural\", \"fr-FR-EloiseNeural\", \"fr-FR-HenriNeural\", \"fr-CH-ArianeNeural\", \"fr-CH-FabriceNeural\", \"gl-ES-RoiNeural\", \"gl-ES-SabelaNeural\", \"ka-GE-EkaNeural\", \"ka-GE-GiorgiNeural\", \"de-AT-IngridNeural\", \"de-AT-JonasNeural\", \"de-DE-SeraphinaMultilingualNeural\", \"de-DE-FlorianMultilingualNeural\", \"de-DE-AmalaNeural\", \"de-DE-ConradNeural\", \"de-DE-KatjaNeural\", \"de-DE-KillianNeural\", \"de-CH-JanNeural\", \"de-CH-LeniNeural\", \"el-GR-AthinaNeural\", \"el-GR-NestorasNeural\", \"gu-IN-DhwaniNeural\", \"gu-IN-NiranjanNeural\", \"he-IL-AvriNeural\", \"he-IL-HilaNeural\", \"hi-IN-MadhurNeural\", \"hi-IN-SwaraNeural\", \"hu-HU-NoemiNeural\", \"hu-HU-TamasNeural\", \"is-IS-GudrunNeural\", \"is-IS-GunnarNeural\", \"id-ID-ArdiNeural\", \"id-ID-GadisNeural\", \"ga-IE-ColmNeural\", \"ga-IE-OrlaNeural\", \"it-IT-GiuseppeNeural\", \"it-IT-DiegoNeural\", \"it-IT-ElsaNeural\", \"it-IT-IsabellaNeural\", \"ja-JP-KeitaNeural\", \"ja-JP-NanamiNeural\", \"jv-ID-DimasNeural\", \"jv-ID-SitiNeural\", \"kn-IN-GaganNeural\", \"kn-IN-SapnaNeural\", \"kk-KZ-AigulNeural\", \"kk-KZ-DauletNeural\", \"km-KH-PisethNeural\", \"km-KH-SreymomNeural\", \"ko-KR-HyunsuNeural\", \"ko-KR-InJoonNeural\", \"ko-KR-SunHiNeural\", \"lo-LA-ChanthavongNeural\", \"lo-LA-KeomanyNeural\", \"lv-LV-EveritaNeural\", \"lv-LV-NilsNeural\", \"lt-LT-LeonasNeural\", \"lt-LT-OnaNeural\", \"mk-MK-AleksandarNeural\", \"mk-MK-MarijaNeural\", \"ms-MY-OsmanNeural\", \"ms-MY-YasminNeural\", \"ml-IN-MidhunNeural\", \"ml-IN-SobhanaNeural\", \"mt-MT-GraceNeural\", \"mt-MT-JosephNeural\", \"mr-IN-AarohiNeural\", \"mr-IN-ManoharNeural\", \"mn-MN-BataaNeural\", \"mn-MN-YesuiNeural\", \"ne-NP-HemkalaNeural\", \"ne-NP-SagarNeural\", \"nb-NO-FinnNeural\", \"nb-NO-PernilleNeural\", \"ps-AF-GulNawazNeural\", \"ps-AF-LatifaNeural\", \"fa-IR-DilaraNeural\", \"fa-IR-FaridNeural\", \"pl-PL-MarekNeural\", \"pl-PL-ZofiaNeural\", \"pt-BR-ThalitaNeural\", \"pt-BR-AntonioNeural\", \"pt-BR-FranciscaNeural\", \"pt-PT-DuarteNeural\", \"pt-PT-RaquelNeural\", \"ro-RO-AlinaNeural\", \"ro-RO-EmilNeural\", \"ru-RU-DmitryNeural\", \"ru-RU-SvetlanaNeural\", \"sr-RS-NicholasNeural\", \"sr-RS-SophieNeural\", \"si-LK-SameeraNeural\", \"si-LK-ThiliniNeural\", \"sk-SK-LukasNeural\", \"sk-SK-ViktoriaNeural\", \"sl-SI-PetraNeural\", \"sl-SI-RokNeural\", \"so-SO-MuuseNeural\", \"so-SO-UbaxNeural\", \"es-AR-ElenaNeural\", \"es-AR-TomasNeural\", \"es-BO-MarceloNeural\", \"es-BO-SofiaNeural\", \"es-CL-CatalinaNeural\", \"es-CL-LorenzoNeural\", \"es-ES-XimenaNeural\", \"es-CO-GonzaloNeural\", \"es-CO-SalomeNeural\", \"es-CR-JuanNeural\", \"es-CR-MariaNeural\", \"es-CU-BelkysNeural\", \"es-CU-ManuelNeural\", \"es-DO-EmilioNeural\", \"es-DO-RamonaNeural\", \"es-EC-AndreaNeural\", \"es-EC-LuisNeural\", \"es-SV-LorenaNeural\", \"es-SV-RodrigoNeural\", \"es-GQ-JavierNeural\", \"es-GQ-TeresaNeural\", \"es-GT-AndresNeural\", \"es-GT-MartaNeural\", \"es-HN-CarlosNeural\", \"es-HN-KarlaNeural\", \"es-MX-DaliaNeural\", \"es-MX-JorgeNeural\", \"es-NI-FedericoNeural\", \"es-NI-YolandaNeural\", \"es-PA-MargaritaNeural\", \"es-PA-RobertoNeural\", \"es-PY-MarioNeural\", \"es-PY-TaniaNeural\", \"es-PE-AlexNeural\", \"es-PE-CamilaNeural\", \"es-PR-KarinaNeural\", \"es-PR-VictorNeural\", \"es-ES-AlvaroNeural\", \"es-ES-ElviraNeural\", \"es-US-AlonsoNeural\", \"es-US-PalomaNeural\", \"es-UY-MateoNeural\", \"es-UY-ValentinaNeural\", \"es-VE-PaolaNeural\", \"es-VE-SebastianNeural\", \"su-ID-JajangNeural\", \"su-ID-TutiNeural\", \"sw-KE-RafikiNeural\", \"sw-KE-ZuriNeural\", \"sw-TZ-DaudiNeural\", \"sw-TZ-RehemaNeural\", \"sv-SE-MattiasNeural\", \"sv-SE-SofieNeural\", \"ta-IN-PallaviNeural\", \"ta-IN-ValluvarNeural\", \"ta-MY-KaniNeural\", \"ta-MY-SuryaNeural\", \"ta-SG-AnbuNeural\", \"ta-SG-VenbaNeural\", \"ta-LK-KumarNeural\", \"ta-LK-SaranyaNeural\", \"te-IN-MohanNeural\", \"te-IN-ShrutiNeural\", \"th-TH-NiwatNeural\", \"th-TH-PremwadeeNeural\", \"tr-TR-AhmetNeural\", \"tr-TR-EmelNeural\", \"uk-UA-OstapNeural\", \"uk-UA-PolinaNeural\", \"ur-IN-GulNeural\", \"ur-IN-SalmanNeural\", \"ur-PK-AsadNeural\", \"ur-PK-UzmaNeural\", \"uz-UZ-MadinaNeural\", \"uz-UZ-SardorNeural\", \"vi-VN-HoaiMyNeural\", \"vi-VN-NamMinhNeural\", \"cy-GB-AledNeural\", \"cy-GB-NiaNeural\", \"zu-ZA-ThandoNeural\", \"zu-ZA-ThembaNeural\"]\n",
        "speech_rate = 0 # @param {\"type\":\"slider\",\"min\":-100,\"max\":100,\"step\":1}\n",
        "#@markdown **Model options: Pitch and Index**\n",
        "model_name = \"\" #@param {\"type\":\"string\",\"placeholder\":\"Model name\"}\n",
        "pitch_shift = 0 #@param {\"type\":\"slider\",\"min\":-20,\"max\":20,\"step\":1}\n",
        "index_influence = 0.5 #@param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.01}\n",
        "#@markdown **Feature extraction options, hop length, voice protection**\n",
        "extraction_method = \"rmvpe\" #@param [\"pm-ac\", \"pm-cc\", \"pm-shs\", \"dio\", \"mangio-crepe-tiny\", \"mangio-crepe-small\", \"mangio-crepe-medium\", \"mangio-crepe-large\", \"mangio-crepe-full\", \"crepe-tiny\", \"crepe-small\", \"crepe-medium\", \"crepe-large\", \"crepe-full\", \"fcpe\", \"fcpe-legacy\", \"rmvpe\", \"rmvpe-legacy\", \"harvest\", \"yin\", \"pyin\", \"swipe\", \"piptrack\", \"fcn\"]\n",
        "hop_length = 64 # @param {\"type\":\"slider\",\"min\":64,\"max\":512,\"step\":1}\n",
        "voice_protection = 0.5 #@param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.1}\n",
        "#@markdown **Options for audio splitting for faster processing, automatic pitch, and output file format**\n",
        "output_file_format = \"wav\" #@param [\"wav\", \"mp3\", \"flac\", \"ogg\", \"opus\", \"m4a\", \"mp4\", \"aac\", \"alac\", \"wma\", \"aiff\", \"webm\", \"ac3\"]\n",
        "split_audio = False #@param {\"type\":\"boolean\"}\n",
        "\n",
        "filename = None\n",
        "if text_input: input_text = text_input\n",
        "else:\n",
        "    print(\"Text field is empty. Please upload a text file (.txt) to proceed with conversion!\")\n",
        "    uploaded = files.upload()\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    input_text = process_input(filename)\n",
        "\n",
        "if model_name:\n",
        "    if not model_name.endswith((\".pth\", \".onnx\")): model_name = model_name + \".pth\"\n",
        "    model_path = os.path.join(\"assets\", \"weights\", model_name)\n",
        "    index_path = get_index(f\"{model_name}.pth\".split(\"_\")[0])\n",
        "else:\n",
        "    model_name = sorted(list(model for model in os.listdir(os.path.join(\"assets\", \"weights\")) if model.endswith((\".pth\", \".onnx\")) and not model.startswith(\"G_\") and not model.startswith(\"D_\")))\n",
        "    indexpath = sorted([os.path.join(root, name) for root, _, files in os.walk(os.path.join(\"assets\", \"logs\"), topdown=False) for name in files if name.endswith(\".index\")])\n",
        "\n",
        "    if len(model_name) < 1: raise ValueError(\"Please provide a model to proceed with conversion!\")\n",
        "    elif len(model_name) == 1:\n",
        "        model_path = os.path.join(\"assets\", \"weights\", model_name[0])\n",
        "        index_path = get_index(os.path.basename(model_name[0])[0])\n",
        "    else:\n",
        "        print(\"Found more than 1 model, please enter the model number to proceed with conversion!\")\n",
        "        for m in model_name:\n",
        "            print(f\"{model_name.index(m)}. {m}\")\n",
        "\n",
        "        while 1:\n",
        "            try:\n",
        "                model_index = int(input(\"Enter the model number: \"))\n",
        "                if 0 <= model_index < len(model_name):\n",
        "                    selected_model = model_name[model_index]\n",
        "                    print(f\"You selected the model: {selected_model}\")\n",
        "                    break\n",
        "                else: print(\"Invalid number. Please try again.\")\n",
        "            except ValueError:\n",
        "                print(\"Please enter an integer.\")\n",
        "            except IndexError:\n",
        "                print(\"Number out of range. Please try again.\")\n",
        "\n",
        "        model_path = os.path.join(\"assets\", \"weights\", selected_model)\n",
        "        index_path = get_index(os.path.basename(selected_model).split(\"_\")[0])\n",
        "\n",
        "if not index_path: print(\"No index found!\")\n",
        "\n",
        "tts_output = os.path.join(\"audios\", f\"tts.{output_file_format}\")\n",
        "convert_tts_output = os.path.join(\"audios\", f\"tts-convert.{output_file_format}\")\n",
        "\n",
        "args = f'from main.app.core.tts import TTS; TTS(\\\\\"{input_text}\\\\\", \\\\\"{voice}\\\\\", {speech_rate}, \\\\\"{tts_output}\\\\\", 0, False, \\\\\"{filename}\\\\\")'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "args = f'from main.app.core.inference import convert_tts; convert_tts(False, False, {pitch_shift}, 0.7, \\\\\"{model_path}\\\\\", \\\\\"{index_path}\\\\\", {index_influence}, \\\\\"{tts_output}\\\\\", \\\\\"{convert_tts_output}\\\\\", \\\\\"{output_file_format}\\\\\", \\\\\"{extraction_method}\\\\\", None, {hop_length}, \\\\\"hubert_base\\\\\", None, 0, 3, 1, {voice_protection}, {split_audio}, 1, False, False, False, 0, 0, \\\\\"None\\\\\", \\\\\"fairseq\\\\\", False, 0)'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "clear_output()\n",
        "print(f\"Your output file is: /content/Vietnamese_RVC/audios/tts-convert.{output_file_format}\")\n",
        "display(Button(description=\"\\u2714 Complete!\", button_style=\"success\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kzVFeANCq2lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training ü§ñ**"
      ],
      "metadata": {
        "id": "9U2vuwoUyiPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìÅ **Create training data from path**\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "%cd /content/main_core\n",
        "\n",
        "#@markdown **Create training data from URL**\n",
        "clean_data = False #@param {\"type\":\"boolean\"}\n",
        "url_path = \"\" #@param {\"type\":\"string\", placeholder:\"URL path\"}\n",
        "\n",
        "args = f'from main.app.core.training import create_dataset; [None for _ in create_dataset(\\\\\"{url_path}\\\\\", \\\\\"dataset\\\\\", False, 0, 0, True, \\\\\"HD_MMI\\\\\", \\\\\"MDX-Reverb\\\\\", \\\\\"Lite\\\\\", 48000, 2, 1, 0.25, 5, 1024, 512, 256, 0.2, False, True, False, False, True, {clean_data}, 0.7)]'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "clear_output()\n",
        "display(Button(description=\"\\u2714 Complete!\", button_style=\"success\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XYssmDxRy4Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title üî® **Data Preprocessing & Feature Extraction** ‚õèÔ∏è\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "%cd /content/main_core\n",
        "\n",
        "#@markdown **Load data from Google Drive to Google Colab for processing and extraction**\n",
        "load_from_drive = False # @param {\"type\":\"boolean\"}\n",
        "#@markdown **Model name for processing**\n",
        "model_name = \"\" #@param {\"type\":\"string\", placeholder: \"Model name\"}\n",
        "#@markdown **Model sampling rate for processing**\n",
        "sampling_rate = \"48k\" #@param [\"32k\", \"40k\", \"48k\"]\n",
        "#@markdown **Pitch extraction method and hop length for the model**\n",
        "extraction_method = \"rmvpe\" #@param [\"pm-ac\", \"pm-cc\", \"pm-shs\", \"dio\", \"mangio-crepe-tiny\", \"mangio-crepe-small\", \"mangio-crepe-medium\", \"mangio-crepe-large\", \"mangio-crepe-full\", \"crepe-tiny\", \"crepe-small\", \"crepe-medium\", \"crepe-large\", \"crepe-full\", \"fcpe\", \"fcpe-legacy\", \"rmvpe\", \"rmvpe-legacy\", \"harvest\", \"yin\", \"pyin\", \"swipe\", \"piptrack\", \"fcn\"]\n",
        "hop_length = 64 # @param {\"type\":\"slider\",\"min\":64,\"max\":512,\"step\":1}\n",
        "\n",
        "if load_from_drive:\n",
        "    if not os.path.exists(\"/content/drive/MyDrive\"): raise ValueError(\"You haven't connected to Google Drive\")\n",
        "    if len([f for f in os.listdir(\"/content/drive/MyDrive/dataset\") if not \".ipynb_checkpoints\" in f]) < 1: raise FileNotFoundError(\"No data found\")\n",
        "\n",
        "    for audios in os.listdir(\"/content/drive/MyDrive/dataset\"):\n",
        "        shutil.copy(f\"/content/drive/MyDrive/dataset/{audios}\", \"/content/Vietnamese_RVC/dataset\")\n",
        "elif not any(f.lower().endswith((\"wav\", \"mp3\", \"flac\", \"ogg\", \"opus\", \"m4a\", \"mp4\", \"aac\", \"alac\", \"wma\", \"aiff\", \"webm\", \"ac3\")) for f in os.listdir(\"/content/Vietnamese_RVC/dataset\") if os.path.isfile(os.path.join(\"/content/Vietnamese_RVC/dataset\", f))):\n",
        "    uploaded = files.upload()\n",
        "    for f in list(uploaded.keys()):\n",
        "        input_path = os.path.join(\"dataset\", os.path.basename(f).replace(' ', '_').replace('(', '').replace(')', '').replace('{', '').replace('}', ''))\n",
        "        shutil.move(f, input_path)\n",
        "\n",
        "if not model_name: raise ValueError(\"Please provide a name to proceed!\")\n",
        "\n",
        "args = f'from main.app.core.training import preprocess; [None for _ in preprocess(\\\\\"{model_name}\\\\\", \\\\\"{sampling_rate}\\\\\", 2, True, True, \\\\\"dataset\\\\\", False, 0.7)]'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "args = f'from main.app.core.training import extract; [None for _ in extract(\\\\\"{model_name}\\\\\", \\\\\"v2\\\\\", \\\\\"{extraction_method}\\\\\", True, {hop_length}, 2, 0, \\\\\"{sampling_rate}\\\\\", \\\\\"hubert_base\\\\\", None, False, \\\\\"fairseq\\\\\", False, 1, None, False)]'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "args = f'from main.app.core.training import create_index; [None for _ in create_index(\\\\\"{model_name}\\\\\", \\\\\"v2\\\\\", \\\\\"Auto\\\\\")]'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "clear_output()\n",
        "display(Button(description=\"\\u2714 Complete!\", button_style=\"success\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6B_JOyUUy0U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title ü§ñ **Model Training**\n",
        "import os\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/main_core\n",
        "\n",
        "#@markdown **Model name and sampling rate for training**\n",
        "model_name = \"\" #@param {\"type\":\"string\", placeholder: \"Model name\"}\n",
        "sampling_rate = \"48k\" #@param [\"32k\", \"40k\", \"48k\"]\n",
        "#@markdown **Number of epochs and save frequency**\n",
        "num_epochs = 300 #@param {\"type\":\"slider\", min:1, max:10000}\n",
        "save_frequency = 50 #@param {\"type\":\"slider\", min:1, max:10000}\n",
        "#@markdown **Batch size options and whether to use cache**\n",
        "batch_size = 10 #@param {\"type\":\"slider\", min:1, max:20}\n",
        "use_cache = False #@param {\"type\":\"boolean\"}\n",
        "#@markdown **Training visualization options, automatic overfitting check, and using custom pre-trained models**\n",
        "use_tensorboard = False #@param {type:\"boolean\"}\n",
        "check_overfitting = False #@param {\"type\":\"boolean\"}\n",
        "use_custom_pretrained = False #@param {\"type\":\"boolean\"}\n",
        "\n",
        "if use_tensorboard:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir ./assets/logs --port=6870\n",
        "\n",
        "if use_custom_pretrained:\n",
        "    model_name = [f for f in os.listdir(os.path.join(\"assets\", \"models\", \"pretrained_custom\")) if f.endswith(\".pth\")]\n",
        "\n",
        "    if len(model_name) == 2:\n",
        "        for m in model_name:\n",
        "            print(f\"{model_name.index(m)}. {m}\")\n",
        "\n",
        "        while 1:\n",
        "            try:\n",
        "                model_index_d = int(input(\"Enter the number for model D: \"))\n",
        "                if 0 <= model_index_d < len(model_name):\n",
        "                    selected_model_D = model_name[model_index_d]\n",
        "                    print(f\"You selected model D: {selected_model_D}\")\n",
        "                    break\n",
        "                else: print(\"Invalid number. Please try again.\")\n",
        "            except ValueError:\n",
        "                print(\"Please enter an integer.\")\n",
        "            except IndexError:\n",
        "                print(\"Number out of range. Please try again.\")\n",
        "\n",
        "        model_name.remove(selected_model_D)\n",
        "        model_index_g = model_name[0]\n",
        "    elif len(model_name) >= 2:\n",
        "        for m in model_name:\n",
        "            print(f\"{model_name.index(m)}. {m}\")\n",
        "\n",
        "        while 1:\n",
        "            try:\n",
        "                model_index_d = int(input(\"Enter the number for model D: \"))\n",
        "                if 0 <= model_index_d < len(model_name):\n",
        "                    selected_model_D = model_name[model_index_d]\n",
        "                    print(f\"You selected model D: {selected_model_D}\")\n",
        "                    break\n",
        "                else: print(\"Invalid number. Please try again.\")\n",
        "            except ValueError:\n",
        "                print(\"Please enter an integer.\")\n",
        "            except IndexError:\n",
        "                print(\"Number out of range. Please try again.\")\n",
        "\n",
        "        while 1:\n",
        "            try:\n",
        "                model_index_g = int(input(\"Enter the number for model G: \"))\n",
        "                if 0 <= model_index_g < len(model_name):\n",
        "                    selected_model_G = model_name[model_index_g]\n",
        "                    print(f\"You selected model G: {selected_model_G}\")\n",
        "                    break\n",
        "                else: print(\"Invalid number. Please try again.\")\n",
        "            except ValueError:\n",
        "                print(\"Please enter an integer.\")\n",
        "            except IndexError:\n",
        "                print(\"Number out of range. Please try again.\")\n",
        "\n",
        "        if selected_model_D == selected_model_G: raise ValueError(\"Model D and G are the same!\")\n",
        "        clear_output()\n",
        "    else: print(\"No pre-trained models found!\")\n",
        "else: selected_model_G = selected_model_D = None\n",
        "\n",
        "\n",
        "args = f'from main.app.core.training import training; [None for _ in training(\\\\\"{model_name}\\\\\", \\\\\"v2\\\\\", {save_frequency}, True, True, {num_epochs}, \\\\\"{sampling_rate}\\\\\", {batch_size}, 0, True, False, {use_custom_pretrained}, \\\\\"{selected_model_G}\\\\\", \\\\\"{selected_model_D}\\\\\", {check_overfitting}, 50, False, {use_cache}, \\\\\"\\\\\", \\\\\"Default\\\\\", False, False, True, \\\\\"AdamW\\\\\", False)]'\n",
        "!python3 -c \"$args\"\n",
        "\n",
        "Button(description=\"\\u2714 Complete!\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pRuwjqoky7lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title üì¶ **Compress and Save Model** üì¶\n",
        "\n",
        "#@markdown **Run this cell and select the model file to compress!**\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def get_index(model):\n",
        "    return next((f for f in [os.path.join(root, name) for root, _, files in os.walk(os.path.join(\"assets\", \"logs\"), topdown=False) for name in files if name.endswith(\".index\") and \"trained\" not in name] if model.split(\".\")[0] in f), \"\")\n",
        "\n",
        "model_name = sorted(list(model for model in os.listdir(os.path.join(\"assets\", \"weights\")) if model.endswith((\".pth\", \".onnx\")) and not model.startswith(\"G_\") and not model.startswith(\"D_\")))\n",
        "indexpath = sorted([os.path.join(root, name) for root, _, files in os.walk(os.path.join(\"assets\", \"logs\"), topdown=False) for name in files if name.endswith(\".index\")])\n",
        "\n",
        "if len(model_name) < 1: raise ValueError(\"Please provide a model to proceed!\")\n",
        "elif len(model_name) == 1:\n",
        "    model_path = os.path.join(\"assets\", \"weights\", model_name[0])\n",
        "    index_path = get_index(os.path.basename(model_name[0])[0])\n",
        "else:\n",
        "    print(\"Found more than 1 model, please enter the model number to proceed!\")\n",
        "    for m in model_name:\n",
        "        print(f\"{model_name.index(m)}. {m}\")\n",
        "\n",
        "    while 1:\n",
        "        try:\n",
        "            model_index = int(input(\"Enter the model number: \"))\n",
        "            if 0 <= model_index < len(model_name):\n",
        "                selected_model = model_name[model_index]\n",
        "                print(f\"You selected the model: {selected_model}\")\n",
        "                break\n",
        "            else: print(\"Invalid number. Please try again.\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter an integer.\")\n",
        "        except IndexError:\n",
        "            print(\"Number out of range. Please try again.\")\n",
        "\n",
        "    model_path = os.path.join(\"assets\", \"weights\", selected_model)\n",
        "    index_path = get_index(os.path.basename(selected_model).split(\"_\")[0])\n",
        "\n",
        "if not index_path: print(\"No index found!\")\n",
        "zip_file_path = os.path.join(\"assets\", os.path.basename(model_path).split(\"_\")[0] + \".zip\")\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
        "    zipf.write(model_path, os.path.basename(model_path))\n",
        "    if index_path: zipf.write(index_path, os.path.basename(index_path))\n",
        "\n",
        "clear_output()\n",
        "print(f\"Your model path: {zip_file_path}\")\n",
        "Button(description=\"\\u2714 Complete!\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7_Z2qvZo4oHa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tkqks7bO2Cye",
        "XP4ifZaG_yd5",
        "ekfkFFNqppfM",
        "ers351v_CMGN"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}